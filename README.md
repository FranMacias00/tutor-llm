# Tutor-LLM

Proyecto que implementa un asistente/tutor educativo basado en modelos de lenguaje (LLM).

El sistema permite:

* Generar preguntas a partir del texto de un documento.
* Evaluar respuestas del usuario frente a una pregunta generada.
* Recomendar recursos (libros, documentaci√≥n, enlaces) seg√∫n la evaluaci√≥n.

La arquitectura est√° dividida en dos partes principales:

* **Backend:** API REST desarrollada con Express.
* **Frontend:** aplicaci√≥n React que consume dicha API.

---

## üìÇ Estructura del repositorio

* `backend/` ‚Äî Servidor Express y l√≥gica de los agentes.

  * `server.js` ‚Äî Punto de entrada del servidor; expone los endpoints REST.
  * `agents/` ‚Äî Implementaciones de los agentes:

    * `QuestionAgent.js` ‚Äî Genera preguntas a partir de texto.
    * `EvaluationAgent.js` ‚Äî Eval√∫a la respuesta del usuario (Correcto/Incorrecto y explicaci√≥n).
    * `RecommendationAgent.js` ‚Äî Recomienda recursos seg√∫n la evaluaci√≥n.
  * `orchestrator/OrchestratorAgent.js` ‚Äî Coordina los agentes y selecciona modelos por defecto.
  * `model/ApiLLM.js` ‚Äî Cliente HTTP que encapsula las llamadas al servicio de LLM (usa `axios`).

* `frontend/` ‚Äî Aplicaci√≥n React que interact√∫a con el backend.

  * `src/components/` ‚Äî Componentes UI (entrada de respuesta, preguntas, recomendaciones, etc.).

* `README.md` ‚Äî (este archivo) documentaci√≥n del proyecto.

---

## ‚öôÔ∏è Requisitos

* Node.js (>= 16 recomendado)
* npm (o yarn)
* Una clave/API y una URL de endpoint para el servicio LLM que se utilizar√° desde `backend/model/ApiLLM.js`

---

## üîê Variables de entorno (backend)

En el fichero `.env` dentro de la carpeta `backend/`, definir las siguientes variables:

```
API_KEY=tu_api_key_aqui
ENDPOINT_URL=https://api.tu-llm.com/v1/generate
PORT=5000
```

---

## üöÄ Instalaci√≥n y ejecuci√≥n

### Backend (API)

1. Abrir una terminal y moverse al directorio `backend`:

   ```bash
   cd backend
   ```

2. Instalar dependencias:

   ```bash
   npm install
   ```

3. Ejecutar el servidor:

   ```bash
   node server.js
   ```

### Frontend (React)

1. En otra terminal, moverse al directorio `frontend`:

   ```bash
   cd frontend
   ```

2. Instalar dependencias y ejecutar:

   ```bash
   npm install
   npm start
   ```

La aplicaci√≥n React se iniciar√° en `http://localhost:3000` por defecto.

---

## üß† Endpoints del API (backend)

Todos los endpoints son **POST** y devuelven **JSON**.

### 1. Generar pregunta

* **Ruta:** `/generate-question`
* **Body JSON:**

  ```json
  { "documentText": "Texto completo del documento o fragmento" }
  ```
* **Respuesta:**

  ```json
  { "question": "[Pregunta]: ..." }
  ```

### 2. Evaluar respuesta

* **Ruta:** `/evaluate-answer`
* **Body JSON:**

  ```json
  {
    "userAnswer": "Respuesta del estudiante",
    "question": "Pregunta previamente generada"
  }
  ```
* **Respuesta:**

  ```json
  {
    "evaluation": "Correcto\nRespuesta del usuario: ...\nExplicaci√≥n..."
  }
  ```

### 3. Recomendar recursos

* **Ruta:** `/recommend-resources`
* **Body JSON:**

  ```json
  {
    "question": "...",
    "userAnswer": "...",
    "evaluation": "..."
  }
  ```
* **Respuesta:**

  ```json
  {
    "recommendations": "Lista de recursos o enlaces en texto"
  }
  ```

---

## üß© Arquitectura y dise√±o

* **ApiLLM** (`backend/model/ApiLLM.js`): cliente HTTP gen√©rico para llamar al servicio LLM. Env√≠a un objeto con `model` y `messages`, y devuelve `response.data.choices[0].message.content`.
* **OrchestratorAgent** (`backend/orchestrator/OrchestratorAgent.js`): orquesta los tres agentes (Question, Evaluation, Recommendation) y selecciona los modelos por defecto (`llama3.1:8b`, `cogito:8b`, `gemma3:12b`).
* **Agentes** (`backend/agents/`): cada uno construye un *prompt* espec√≠fico y usa `ApiLLM.call()` para obtener respuestas.

**Flujo t√≠pico:**

1. El frontend env√≠a el texto del documento a `/generate-question`.
2. El `OrchestratorAgent` invoca a `QuestionAgent` para generar una pregunta.
3. El usuario responde en el frontend y env√≠a su respuesta a `/evaluate-answer`.
4. `EvaluationAgent` formatea un prompt para evaluar la respuesta y generar una explicaci√≥n.
5. Seg√∫n el resultado, el frontend llama a `/recommend-resources` para obtener recursos adicionales.

---

## üóÇÔ∏è Ficheros clave

* `backend/server.js` ‚Äî arranque y endpoints del servidor
* `backend/orchestrator/OrchestratorAgent.js` ‚Äî coordinaci√≥n de agentes
* `backend/model/ApiLLM.js` ‚Äî cliente de llamadas a LLM
* `backend/agents/QuestionAgent.js`, `EvaluationAgent.js`, `RecommendationAgent.js` ‚Äî l√≥gica y prompts de cada agente

---

## üë®‚Äçüíª Autor

**Francisco Javier Mac√≠as Villa√©cija**  
Ingeniero Inform√°tico  
[GitHub](https://github.com/FranMacias00)

